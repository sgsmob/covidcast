---
title: "Delphi's COVIDcast Project: <br> COVID-19 Symptom Surveys Through Facebook"
author: Alex Reinhart\* and Ryan Tibshirani^†^ <br> \*^†^Statistics and ^†^Machine Learning <br> Carnegie Mellon University <br> ^†^Amazon Scholar, AWS Labs
date: "<br> ![](delphi.png) ![](cmu.png) <br><br> September 8, 2020"
footer: "Get the slides at: cmu-delphi.github.io/covidcast/talks/fb-survey/talk.html"
output: 
  slidy_presentation:
    theme: cerulean
    highlight: tango
    font_adjustment: +1
    css: style.css
    includes: 
      after_body: script.html
---

```{r, include = FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE, cache=TRUE, autodep=TRUE, 
                      cache.comments=TRUE)
library(dplyr)
library(ggplot2)
library(gridExtra)

col = function(x, color = "#bb0000") {
  sprintf("<span style='color: %s;'>%s</span>", color, x)
}
```

# COVIDcast

The COVIDcast project has many parts: 
    
1. Unique relationships with partners in tech and healthcare granting us access to data on pandemic activity
2. Code and infrastructure to build `r col("COVID-19 indicators")`, continuously-updated and geographically-comprehensive
3. A historical database of all indicators, including `r col("revision tracking")`, with over 500 million observations
4. A [public API](https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html) serving new indicators daily (and [R and Python packages](https://cmu-delphi.github.io/delphi-epidata/api/covidcast_clients.html) for client support)
5. [Interactive maps and graphics](https://covidcast.cmu.edu) to display our indicators
6. `r col("Forecasting and modeling")` work building on the indicators

# Severity Pyramid

![](severity_pyramid.svg)

# COVIDcast Indicators

![](covidcast_indicators.svg)

# COVIDcast Indicators (Cont.)

- Available through the [COVIDcast API](https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html), updated daily
- Most (nearly all) available at the `r col("county level")`
- For a full list see our [signal documentation site](https://cmu-delphi.github.io/delphi-epidata/api/covidcast_signals.html) 
- Provide [R and Python packages](https://cmu-delphi.github.io/delphi-epidata/api/covidcast_clients.html) for client support

# This Talk

Today: Our COVID-19 symptom surveys through Facebook. Outline:

- Survey background and basics
- Early indicator of COVID activity?
- Other data available from the survey

<br>

Upcoming talks: medical claims data, forecast evaluation, etc.

# Our Two Surveys 

Back in March 2020, we began discussions with Facebook and Google about running surveys to collect real-time info on COVID symptoms. In April we launched two surveys: 

- One advertised by Facebook, and implemented on our own CMU platform 
- One run by Google through Google's Opinions Reward app, AdMob, etc.

<br>

Both are `r col("massive")`. But they are are very different:

- Facebook survey: long, and no control over geo-sampling distribution 
- Google survey: short, and full control over geo-sampling distribution

We'll cover the Google survey another time (still very much a work in progress)

# Our Facebook Survey

Through recruitment partnership with Facebook, we survey about `r col("75,000 people daily")` (over 10 million since April) in the United States about:

- COVID symptoms (common and rare)
- COVID testing
- Mental health
- Social contacts and behavior
- Mask wearing (launched today!)
- Demographics

A [parallel, international effort](https://covidmap.umd.edu/) by the University of Maryland reaches 100+ countries in 55 languages; over 20 million responses so far

# Our Facebook Survey (Cont.)

- The US survey is implemented on Qualtrics, managed by CMU
- Facebook never receives any individual responses
- Designed to take about 10 minutes; about 35 questions
- Questions selected for relevance to forecasting and nowcasting
- But also for research in public health (understanding the pandemic burden)
- Respondents provide ZIP code, so data is available at county level

This is the largest non-Census research survey `r col("ever conducted")` (that we know of)

# COVID-Like Illness

Using the survey data we generate daily, county-level estimates of:

- `r col("% CLI")`: the percentage of people with COVID-like illness
- `r col("% CLI-in-community")`: the percentage of people who know someone in their local community with COVID-like illness

(Note that COVID-like illness or CLI is defined as *fever of at least 100 °F, along with cough, shortness of breath, or difficulty breathing*. We also ask people to report on more rare symptoms)

# Why % CLI-in-Community? 

Why ask a proxy question (have people report on others)? You'd be surprised ... this appears to be pretty valuable! Here's Spearman correlations to COVID-19 case rates sliced by time: 

```{r, fig.width=7, fig.height=5}
library(covidcast)

# Fetch Facebook % CLI signal, % CLI-in-community signal and confirmed case
# incidence proportions
start_day = "2020-04-15"
end_day = "2020-09-05"
sympt1 = covidcast_signal("fb-survey", "smoothed_cli", 
                          start_day, end_day)
sympt2 = covidcast_signal("fb-survey", "smoothed_hh_cmnty_cli", 
                          start_day, end_day)
cases = covidcast_signal("usa-facts", "confirmed_7dav_incidence_prop", 
                         start_day, end_day)

# Consider only counties with at least 500 cumulative cases so far
case_num = 500
geo_values = covidcast_signal("usa-facts", "confirmed_cumulative_num",
                              max(cases$time), max(cases$time)) %>%
  filter(value >= case_num) %>% pull(geo_value)
sympt1_act = sympt1 %>% filter(geo_value %in% geo_values)
sympt2_act = sympt2 %>% filter(geo_value %in% geo_values)
cases_act = cases %>% filter(geo_value %in% geo_values)

# Compute correlations, per time, over all counties
df_cor1 = covidcast_cor(sympt1_act, cases_act, by = "time_value", 
                        method = "spearman")
df_cor2 = covidcast_cor(sympt2_act, cases_act, by = "time_value", 
                        method = "spearman")

# Red, blue (similar to ggplot defaults), then yellow
ggplot_colors = c("#FC4E07", "#00AFBB", "#E7B800")

# Stack rowwise into one data frame, then plot time series
df_cor = rbind(df_cor1, df_cor2)
df_cor$signal = c(rep("% CLI", nrow(df_cor1)), 
                  rep("% CLI-in-community", nrow(df_cor2)))
ggplot(df_cor, aes(x = time_value, y = value)) + 
  geom_line(aes(color = signal)) +
  scale_color_manual(values = ggplot_colors[c(3, 1)]) +
  labs(title = "Correlation between survey signals and case rates (by time)",
       subtitle = sprintf("Over all counties with at least %i cumulative cases",
                          case_num), x = "Date", y = "Correlation") +
    theme_bw() + theme(legend.pos = "bottom", legend.title = element_blank())
```

# Why % CLI-in-Community? (Cont.)

Now here's Spearman correlations to COVID-19 case rates sliced by county: 

```{r, fig.width=7, fig.height=5}
# Compute correlations, per time, over all counties
df_cor1 = covidcast_cor(sympt1_act, cases_act, by = "geo_value", 
                        method = "spearman")
df_cor2 = covidcast_cor(sympt2_act, cases_act, by = "geo_value", 
                        method = "spearman")

# Stack rowwise into one data frame, then plot time series
df_cor = rbind(df_cor1, df_cor2)
df_cor$signal = c(rep("% CLI", nrow(df_cor1)), 
                  rep("% CLI-in-community", nrow(df_cor2)))
ggplot(df_cor, aes(value)) + geom_density(aes(color = signal, fill = signal), 
                                          alpha = 0.4) +
  scale_color_manual(values = ggplot_colors[c(3,1)]) +
  scale_fill_manual(values = ggplot_colors[c(3,1)]) +
  labs(title = "Correlation between survey signals and case rates (by county)",
       subtitle = sprintf("Over all counties with at least %i cumulative cases",
                          case_num), x = "Date", y = "Correlation") +
    theme_bw() + theme(legend.pos = "bottom", legend.title = element_blank())
```

# An Early Indicator?

Let's take a look at case counts in Miami-Dade, from June 1 to July 15, and compare it to the % CLI-in-community indicator based on our survey: 

```{r, fig.width=7, fig.height=5}
# Fetch Facebook % CLI-in-community signal and confirmed case incidence numbers
# from June 1 to July 15
start_day = "2020-06-01"
end_day = "2020-07-15"
sympt = covidcast_signal("fb-survey", "smoothed_hh_cmnty_cli", 
                         start_day, end_day)
cases = covidcast_signal("usa-facts", "confirmed_7dav_incidence_num",
                         start_day, end_day)

# Function to transform from one range to another
trans = function(x, from_range, to_range) {
  (x - from_range[1]) / (from_range[2] - from_range[1]) *
    (to_range[2] - to_range[1]) + to_range[1]
}

# Function to produce a plot comparing the signals for one county
plot_one = function(geo_value, title = NULL, xlab = NULL,
                    ylab1 = NULL, ylab2 = NULL, legend =  TRUE) {
  # Filter down the signal data frames
  given_geo_value = geo_value
  sympt_one = sympt %>% filter(geo_value == given_geo_value)
  cases_one = cases %>% filter(geo_value == given_geo_value)
  
  # Compute ranges of the two signals
  range1 = cases_one %>% select("value") %>% range
  range2 = sympt_one %>% select("value") %>% range
  
  # Convenience functions for our two signal ranges
  trans12 = function(x) trans(x, range1, range2)
  trans21 = function(x) trans(x, range2, range1)

  # Find state name, find abbreviation, then set title
  state_name = fips_to_name(paste0(substr(geo_value, 1, 2), "000"))
  state_abbr = name_to_abbr(state_name)
  title = paste0(fips_to_name(geo_value), ", ", state_abbr)

  # Transform the combined signal to the incidence range, then stack
  # these rowwise into one data frame
  df = select(rbind(sympt_one %>% mutate_at("value", trans21),
                    cases_one), c("time_value", "value"))
  df$signal = c(rep("% CLI-in-community", nrow(sympt_one)),
                rep("New COVID-19 cases", nrow(cases_one)))
  
  # Finally, plot both signals
  pos = ifelse(legend, "bottom", "none")
  return(ggplot(df, aes(x = time_value, y = value)) +
           geom_line(aes(color = signal)) +
           scale_color_manual(values = ggplot_colors[1:2]) +
           scale_y_continuous(name = ylab1, limits = range1,
                              sec.axis = sec_axis(trans = trans12,
                                                  name = ylab2)) +
           labs(title = title, x = xlab) + theme_bw() +
           theme(legend.pos = pos, legend.title = element_blank()))
}

# Produce a plot for Miami-Dade, and add vertical lines
plot_one(name_to_fips("Miami-Dade"), xlab = "Date",
         ylab1 = "Daily new confirmed COVID-19 cases",
         ylab2 = "% of people who know someone with CLI") +
  geom_vline(xintercept = as.numeric(as.Date("2020-06-19")),
             linetype = 2, size = 1, color = ggplot_colors[1]) +
  geom_vline(xintercept = as.numeric(as.Date("2020-06-25")),
             linetype = 2, size = 1, color = ggplot_colors[2])
```

# An Early Indicator? (Cont.) 

Ok, that was just one county... let's look at the top 20 in terms of the rise in case counts:

```{r, fig.width=10, fig.height=10}
num = 20
geo_values = cases %>% group_by(geo_value) %>%
  summarize(diff = last(value) - first(value)) %>%
  arrange(desc(diff)) %>% head(num) %>% pull(geo_value)

p_list = vector("list", num)
for (i in 1:num) {
  p_list[[i]] = plot_one(geo_values[i], legend = FALSE)
}
do.call(grid.arrange, c(p_list, nrow = 5, ncol = 4))
```

# An Early Indicator? (Cont.) 

- Facebook % CLI-in-community indicator is never lagging, `r col("sometimes leading")`
- Similar results hold with doctor's visit indicator (but, remember: latency and backfill!)
- Unfortunately, whether leading-or-not seems to be quite location dependent
- We're working on formalizing these findings currently, via hotspot detection models

# Upcoming Data Streams

New revision of the survey will allow us to calculate new aggregates:

- Test positivity rate, broken down by test reason
- Percentage of population tested in last 14 days, broken down by age, occupation
- Percentage of people *ever* tested
- Types of activities people do outside their homes
- Mask wearing
- Anxiety, depression, isolation

Data to become available later this month

# Access to Survey Microdata

Want to study a problem that can be answered with 10 million US survey responses since April? Possible topics:

- Symptoms reported by people testing positive, stratified by chronic conditions, age, etc.
- Test rates and availability by employment and occupation
- Mental health impacts of interventions
- Disparate impacts on minorities and disadvantaged groups
- ... anything else you can think of

Raw response data is freely available to researchers who sign a [data use agreement](https://dataforgood.fb.com/docs/covid-19-symptom-survey-request-for-data-access/) to protect confidentiality of responses

We're `r col("building a network")` of academic and non-profit researchers to learn from the survey. Join us!

# More Links

- [Technical documentation for our Facebook signals](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/fb-survey.html)
- [Full description of survey questions and coding](https://cmu-delphi.github.io/delphi-epidata/symptom-survey/)
- [Blog post on exploring our Facebook signals](https://delphi.cmu.edu/blog/2020/08/26/covid-19-symptom-surveys-through-facebook/)
- [Symptom survey challenge (100k in prizes!)](https://www.symptomchallenge.org)

# Thanks

Many thanks to: 

- The [whole Delphi team](https://covidcast.cmu.edu/covid19-response-team.html), and various CMU units
- Google, Facebook, and Amazon Web Services
- SafeGraph, Quidel, Qualtrics
- Centers for Disease Control and Prevention

Go to: <https://covidcast.cmu.edu> ... you'll find everything linked from there!

<br>

![Delphi](delphi.png) ![Carnegie Mellon University](cmu.png)